# 游꿟 Cr칤ticas de Pel칤culas

Trabajo Pr치ctico para la materia **Organizaci칩n de Datos** (95.58)

---

## 游논 Integrantes

| Nombre                         | GitHub                                   |
|--------------------------------|------------------------------------------|
| Sebasti치n Brizuela             |                                          |
| Luc칤a Agha Zadeh Dehdeh        | [Lucia-azd](https://github.com/Lucia-azd)|
| Juan Sebasti치n Del R칤o         | [S2JuanS2](https://github.com/S2JuanS2)  |

---

## 游닇 Descripci칩n

El objetivo de este trabajo es predecir si una cr칤tica cinematogr치fica es positiva o negativa utilizando diferentes modelos de clasificaci칩n.

### An치lisis Exploratorio

Se trabaj칩 con un DataFrame de **50,000 filas** y **3 columnas** que incluye el ID, las cr칤ticas (en espa침ol) y el sentimiento asociado.

### Preprocesamiento

- Se eliminaron cr칤ticas en ingl칠s, quedando **48,183 cr칤ticas** en espa침ol.
- Se limpiaron caracteres especiales y se transformaron las etiquetas de sentimiento a **1** (positivo) y **0** (negativo).
- Se utiliz칩 **TfidfVectorizer** para ponderar la frecuencia de palabras, eliminando stopwords en espa침ol.

### Modelos Utilizados

- **Bayes Naive**
- **Random Forest**
- **XGBoost**
- **Redes Neuronales**
- **Stacking**

---

## 游늵 Resultados

| Modelo                 | F1      | Precisi칩n | Recall   | Accuracy | Kaggle   |
|------------------------|---------|-----------|----------|----------|----------|
| Bayes Naive (Mejor)    | 0.86911 | 0.85916   | 0.87930  | 0.86748  | 0.75033  |
| Random Forest          | 0.85331 | 0.83575   | 0.87163  | 0.85005  | 0.72281  |
| XGBoost                | 0.86025 | 0.85134   | 0.86934  | 0.85866  | 0.70478  |
| Red Neuronal           | 0.87670 | 0.87670   | 0.87670  | 0.87670  | 0.74471  |
| Stacking               | 0.86764 | 0.84533   | 0.89116  | 0.86293  | 0.74626  |

---

## 游늷 Conclusiones Generales

- El an치lisis exploratorio fue limitado, ya que solo hab칤a una caracter칤stica a analizar (cr칤ticas).
- Las tareas de preprocesamiento resultaron 칰tiles para agilizar y mejorar las predicciones; la eliminaci칩n de cr칤ticas en ingl칠s tuvo un impacto significativo.
- El mejor modelo result칩 ser **Bayes Naive**, el m치s sencillo y r치pido de entrenar, adem치s de ser el que mejor desempe침o tuvo en Kaggle.

---

## 游닇 Licencia

Este proyecto est치 bajo la Licencia MIT. Consulta el archivo [LICENSE](LICENSE) para m치s informaci칩n.
